{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fancy term for this 'if the node would be negative then set it to  0' logic is called a nonlinearity.\n",
    "\n",
    "There are many kinds of nonlinearities. However, the one we discussed above, in many cases, the best one to use. It is called 'relu'.\n",
    "\n",
    "Adjusting our weights to reduce our error over a series of training examples ultimately just searches for correlation between our input and output layers. If no correlation exists,then error will never reach 0.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
